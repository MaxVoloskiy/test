{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.,   0.,   0.,  13.,\n",
       "         15.,  10.,  15.,   5.,   0.,   0.,   3.,  15.,   2.,   0.,  11.,\n",
       "          8.,   0.,   0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.,   0.,\n",
       "          5.,   8.,   0.,   0.,   9.,   8.,   0.,   0.,   4.,  11.,   0.,\n",
       "          1.,  12.,   7.,   0.,   0.,   2.,  14.,   5.,  10.,  12.,   0.,\n",
       "          0.,   0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[ :1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.target\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Начнем с логистической регрессии LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Создадим лист куда будем записывать модель и полученную точность\n",
    "models_accuracy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "lr = LogisticRegression(multi_class='multinomial',  penalty='l2', solver='lbfgs')\n",
    "C_s = np.linspace(0.1, 2, 10)\n",
    "for C in C_s:\n",
    "    lr.C = C\n",
    "    accuracies.append(np.mean(cross_val_score(lr, X, y, cv=sss, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение С = 0.1, точность = 0.961\n",
      "Значение С = 0.31, точность = 0.966\n",
      "Значение С = 0.52, точность = 0.969\n",
      "Значение С = 0.73, точность = 0.966\n",
      "Значение С = 0.94, точность = 0.966\n",
      "Значение С = 1.16, точность = 0.961\n",
      "Значение С = 1.37, точность = 0.961\n",
      "Значение С = 1.58, точность = 0.967\n",
      "Значение С = 1.79, точность = 0.966\n",
      "Значение С = 2.0, точность = 0.965\n"
     ]
    }
   ],
   "source": [
    "for C, accuracy in zip(C_s, accuracies):\n",
    "    print(\"Значение С = {}, точность = {}\".format(round(C,2), round(accuracy, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.C = C_s[accuracies.index(max(accuracies))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_accuracy[lr] = max(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем нашу первую полученную модель и ее точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{LogisticRegression(C=0.52222222222222225, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "           random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "           warm_start=False): 0.9688888888888888}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переходим к рассмотрению решающего дерева DecisionTreeClassifier (код с занятия)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = []\n",
    "depths = list(range(2, 20))\n",
    "for depth in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    means.append(cross_val_score(estimator=clf, X=X, y=y, scoring='accuracy', cv=sss).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Глубина дерева = 2, точность = 0.326\n",
      "Глубина дерева = 3, точность = 0.467\n",
      "Глубина дерева = 4, точность = 0.563\n",
      "Глубина дерева = 5, точность = 0.669\n",
      "Глубина дерева = 6, точность = 0.743\n",
      "Глубина дерева = 7, точность = 0.818\n",
      "Глубина дерева = 8, точность = 0.838\n",
      "Глубина дерева = 9, точность = 0.849\n",
      "Глубина дерева = 10, точность = 0.852\n",
      "Глубина дерева = 11, точность = 0.851\n",
      "Глубина дерева = 12, точность = 0.848\n",
      "Глубина дерева = 13, точность = 0.871\n",
      "Глубина дерева = 14, точность = 0.856\n",
      "Глубина дерева = 15, точность = 0.853\n",
      "Глубина дерева = 16, точность = 0.859\n",
      "Глубина дерева = 17, точность = 0.873\n",
      "Глубина дерева = 18, точность = 0.848\n",
      "Глубина дерева = 19, точность = 0.854\n"
     ]
    }
   ],
   "source": [
    "for depth, mean in zip(depths, means):\n",
    "    print(\"Глубина дерева = {}, точность = {}\".format(round(depth,2), round(mean, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие результаты показали деревья глубиной от 9 до 19. Самую большую точность имеет дерево глубиной - 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.max_depth = depths[means.index(max(means))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_accuracy[clf] = max(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{LogisticRegression(C=0.52222222222222225, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "           random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "           warm_start=False): 0.9688888888888888,\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=17,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'): 0.87277777777777776}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рассмотрим следующий алгоритм SVM.\n",
    "Рассмотрим различные параметры C. Параметр С позволяет находить компромисс между максимизацией разделяющей полосы и минимизацией суммарной ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_s = np.logspace(-10, 0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = []\n",
    "for C in C_s:\n",
    "    svc.C = C\n",
    "    means.append(np.mean(cross_val_score(svc, X, y, scoring='accuracy', cv=sss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.1\n",
      "Параметр штрафа С = 0.0, точность = 0.194\n",
      "Параметр штрафа С = 0.0, точность = 0.812\n",
      "Параметр штрафа С = 0.0, точность = 0.933\n",
      "Параметр штрафа С = 0.0, точность = 0.957\n",
      "Параметр штрафа С = 0.0, точность = 0.974\n",
      "Параметр штрафа С = 0.0, точность = 0.982\n",
      "Параметр штрафа С = 0.0, точность = 0.982\n",
      "Параметр штрафа С = 0.0, точность = 0.979\n",
      "Параметр штрафа С = 0.01, точность = 0.981\n",
      "Параметр штрафа С = 0.02, точность = 0.978\n",
      "Параметр штрафа С = 0.06, точность = 0.983\n",
      "Параметр штрафа С = 0.15, точность = 0.979\n",
      "Параметр штрафа С = 0.38, точность = 0.978\n",
      "Параметр штрафа С = 1.0, точность = 0.982\n"
     ]
    }
   ],
   "source": [
    "for c, mean in zip(C_s, means):\n",
    "    print(\"Параметр штрафа С = {}, точность = {}\".format(round(c, 2), round(mean, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.C = C_s[means.index(max(means))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_accuracy[svc] = max(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{SVC(C=0.056234132519034911, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False): 0.98277777777777775,\n",
       " LogisticRegression(C=0.52222222222222225, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "           random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "           warm_start=False): 0.9688888888888888,\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=17,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'): 0.87277777777777776}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим метод KNN (метод ближайших соседей)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "weights = ['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_uniform = []\n",
    "#Рассмотрим сначала модель, где от расстояния не зависит вес\n",
    "knn.weights = 'uniform'\n",
    "for n_neighbors in list(range(2, 10)):\n",
    "    knn.n_neighbors = n_neighbors\n",
    "    means_uniform.append(np.mean(cross_val_score(knn, X, y, scoring='accuracy', cv=sss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.98777777777777787,\n",
       " 0.98944444444444435,\n",
       " 0.98888888888888893,\n",
       " 0.99111111111111116,\n",
       " 0.9850000000000001,\n",
       " 0.98388888888888881,\n",
       " 0.98277777777777775,\n",
       " 0.97888888888888881]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_distance = []\n",
    "#Рассмотрим сначала модель, где от расстояния не зависит вес\n",
    "knn.weights = 'distance'\n",
    "for n_neighbors in list(range(2, 10)):\n",
    "    knn.n_neighbors = n_neighbors\n",
    "    means_distance.append(np.mean(cross_val_score(knn, X, y, scoring='accuracy', cv=sss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.98833333333333351,\n",
       " 0.99222222222222223,\n",
       " 0.98333333333333339,\n",
       " 0.98944444444444457,\n",
       " 0.98166666666666669,\n",
       " 0.99222222222222212,\n",
       " 0.98777777777777787,\n",
       " 0.98555555555555563]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(means_uniform) > max(means_distance) #чуть лучше оказалась модель, где учитывется расстоние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.n_neighbors = list(range(2, 10))[means_distance.index(max(means_distance))]\n",
    "knn.weights = 'distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_accuracy[knn] = max(means_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{SVC(C=0.056234132519034911, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False): 0.98277777777777775,\n",
       " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "            weights='distance'): 0.99222222222222223,\n",
       " LogisticRegression(C=0.52222222222222225, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "           random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "           warm_start=False): 0.9688888888888888,\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=17,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'): 0.87277777777777776}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решающие деревья показали очень низкую точнсть, попробуем использовать ансамбли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amoun_estimators = list(range(2, 100, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for n_estimators in amoun_estimators:\n",
    "    rfc.n_estimators = n_estimators\n",
    "    means.append(np.mean(cross_val_score(rfc, X, y, scoring='accuracy', cv=sss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.78277777777777779,\n",
       " 0.93777777777777782,\n",
       " 0.96055555555555561,\n",
       " 0.9655555555555555,\n",
       " 0.96444444444444444,\n",
       " 0.97166666666666646,\n",
       " 0.97111111111111104,\n",
       " 0.98111111111111104,\n",
       " 0.9722222222222221,\n",
       " 0.97777777777777786,\n",
       " 0.97666666666666657,\n",
       " 0.97277777777777774,\n",
       " 0.97944444444444445,\n",
       " 0.97944444444444445,\n",
       " 0.97833333333333328,\n",
       " 0.97499999999999998,\n",
       " 0.97944444444444445,\n",
       " 0.97722222222222221,\n",
       " 0.97888888888888892,\n",
       " 0.97166666666666646]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc.n_estimators = amoun_estimators[means.index(max(means))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_accuracy[rfc] = max(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{SVC(C=0.056234132519034911, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False): 0.98277777777777775,\n",
       " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "            weights='distance'): 0.99222222222222223,\n",
       " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=37, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False): 0.98111111111111104,\n",
       " LogisticRegression(C=0.52222222222222225, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='multinomial', n_jobs=1, penalty='l2',\n",
       "           random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "           warm_start=False): 0.9688888888888888,\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=17,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'): 0.87277777777777776}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги. \n",
    "Самая худшая модель - DecisionTreeClassifier с точностью  = __0.873__, самая лучшая модель - KNeighborsClassifier с точностью = __0.992__. \n",
    "В KNeighborsClassifier используем следующие параметры: \n",
    "* количество соседей (__n_neighbors__) = 3\n",
    "* веса (__weights__) = 'distance', то есть дальность напрямую влияет на расчет в модели"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
